---
title: Daily work 
tags:
	- daily work
categories:
	- diaries
date: 
---

---
title: Finally about to get my own research topic
tags:
  - daily work
  - skelevision
categories:
  - diaries
date: 04-07-2023 
---
# What I have done today

1. Installed 4090 GPU on tower server and configured its driver.
2. Reproduced the [skelevison](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13864) paper with their data and preliminary attempted with my own data. It is still hard to say I can make it work for me, but it does present a initial results which is that each part can be identified under man-made annotations when I use the [scripts](https://github.com/bcweeks/Skelevision) provided on github.
3. Reported the second point mentioned above to my supervisor.

# What I need to do next

1. Install the only left 8-pin power cord for the GPU. [Done](https://zhangdeweb.site/2023/04/08/04-08-2023/)
2. Read literature, evaluate the feasibility of this method. Write my dissertation report. 
	Given a new [research](https://doi.org/10.1016/j.pld.2022.11.001) using a similar approach to study phylogeny, my original idea may be feasible. 
	- However, I need to find out a new innovation point for my own project. Specifically, I need deal with trait definition and quantification, modeling the evolution process against this data type, evaluate trait quality in evolutionary analyse, combine multimodal data like pictures and molecular sequences. 
	- Since this is a PhD project, I need to assess whether I can achieve enough results to meet my graduation requirements. Namely I need to plan to publish 3 articles at least.

# What I want to do in future
- Continue configure my edit environment in archlinux with old laptop. [Done](https://zhangdeweb.site/2023/04/08/04-08-2023/)
- Summarize installation and configuration of archlinux.

# What I want to tell myself
Read papers first. Find out the key issue. Clarify my research ideas and logic. 
It should be excited for me that finally about to get my own research topic and I need to think over and plan it very carefully.


---
title: A normal day with something forgotten
tags:
  - daily work
categories:
  - diaries
date: 04-08-2023
---
# What I have done today

1. Install 4090 GPU power cord.
2. Did some housework.
3. Installed hexo blog environment and something else in old laptop.
4. Organize all pictures from Dr. Liang Zonglei and process them with train.py and predict.py.

# What I need to do next

1. Add a curtain to my tower chassis.
2. Add a GPU physical support. [Done](https://zhangdeweb.site/2023/04/09/04-09-2023/)
3. Sting out the margin.
4. Study with the annotation and learn how to definition traits like them.
5. Add internal links among blog articles. [Done](https://zhangdeweb.site/2023/04/10/04-10-2023/)

# What I want to do in future
- Write down archlinux blog environment installing process. Including fcitx, xorg, i3wm, obsidian, vial with linux install, clash for windows with [tun mod in linux](https://github.com/Fndroid/clash_for_windows_pkg/issues/3464), zsh, zim, p10k, exa, neovim with ^M problem, vim-plug, and others.
- Deal with the problem that firefox web browser cannot visit google. [Done](https://zhangdeweb.site/2023/04/10/04-10-2023/)

# What I want to tell myself
Today is Saturday. Be busy tomorrow.


---
title: Sunday, I have to be busy tomorrow.
tags:
  - daily work
  - git
  - vim
categories:
  - diaries
date: 04-09-2023
---
# What I have done today

1. Added the GPU support.
2. Configured zimfw and zsh-z for tower.
3. Configured Lightdm for tower followed by <https://blog.csdn.net/caoshiying/article/details/107242980>.
	`.gz` files need a `gzip` tool by command `gzip -c <*>.gz > <output_file>`.
# What I need to do next

1. Nothing should be continued by today's work.

# What I want to do in future
- Works left before.

# What I want to tell myself
`Git` is a useful tool when dealing with complex objects. I have used it several times but I don't understand its basic logic clearly. Today, I re-learned `Git` and document my notes.
 - `git add` add files to track. A new file created in workspace needs this command to be added in git's track and controlled by git. Changed files controlled by git in the workspace also need this command to be added in storage.
 - `git commit` sent files in storage to local repository.
 - `git push` push local commits to remote repository.
 - `git log` check commit histories. Use `-h` followed by the command to check more info.
 - `git reset` back to specified state. `git revert` revert existing commits.
 - `git rm` remove files in storage.
 - `git pull` sync **workspace** to the remote repository. If workspace have been changed after latest version from remote repository, move or remove local files.
That's it right now. Others more complicated will be learned when I meet it.

Another tips I have learned today is that how to add or cancel comments in VIM.
- `ctrl + q` to enter visual block mode.
- use "hjkl" or other command keys to select range to be changed.
- `shift + i` to enter insert mode.
- Add comment symbol on the first line.
- Press `esc` to quit insert mode and the range selected will be added symbols typed before.
This method can be used to many situations. If you want to cancel the comments, press `x` to delete comment symbols after selecting range.


---
title: A day with fails and conda.
tas:
  - daily work
  - i3wm
  - blog
  - 2022se
categories:
  - diaries
date: 04-10-2023
---
# What I have done today

1. Added internal links among my daily blogs. [More info](https://blog.jijian.link/2020-01-08/hexo-anchor-link/#hexo-%E6%A0%87%E9%A2%98%E4%B8%8E-id-%E5%85%B3%E7%B3%BB)
	Something about attachments in blog: 
	- Configure hexo and use source file folder. Follow [this](https://hexo.io/zh-cn/docs/asset-folders).
	- `.md` files always appear on the homepage wherever it locates in sources folder or not. `.txt` will present contents on the web page. Files without `.*` will be download to local.
	- Use `[](*.*)` to cite files in source.  **`.*`** **is always suggested to be added.**
	- Obsidian is not a good tools to deal with attachments. It does not show files which is not followed by `.md`. Maybe configuring neovim more carefully is a good  idea. 
1. Configured `Aur` source for `yay` in archlinux running on my old laptop.
	In this way, the [problem](https://zhangdeweb.site/2023/04/08/04-08-2023/) of firefox has been solved by the way, which can be replaced by configures of chrome. Just do `yay -S google-chrome` and follow [this](https://onlycaptain.github.io/2018/10/01/Ubuntu%E4%B8%8Bgoogle%E4%B8%8D%E8%83%BD%E6%AD%A3%E7%A1%AE%E4%BB%A3%E7%90%86%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/).
3. Tried to reproduced the [2022SE](https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/syen.12543) used [scripts](https://github.com/alexander-pv/insects-recognition) from github. But my conda cannot install all dependency and stopped at train step. Maybe the configures of sources of conda is wrong. 
	The reason why I reproduced this article is that I want to try if the recognition with non-man-made annotations can split pictures and how much it refines the outlines.

# What I need to do next

1. Structures outline definition.
2. Annotation changing.
3. Traits definition. Maybe same thing to the first point.

# What I want to do in future
- Archlinux configure process.
- Conda configuration.
- Hexo or other blogs custom configure.

# What I want to tell myself
**Shortcuts** is a basic operation of daily use but I cannot use or custom them easily before, especially when I used `Vial` to custom my *ergo* keyboard. Today I get a new useful tool, `xev`, from [here](https://www.cnblogs.com/yinheyi/p/10146900.html) to confirm my key coding includes values of 'keysym' and 'keycode'. Now I can configure my own shortcuts in **i3wm** with command `bindsym` for 'keysym' and `bindcode` for 'keycode' in `~/.config/i3/config`. And here is my [config file](configfile_i3wm.txt). 



---
title: I don't want to depend with the dependency
tags:
  - daily work
  - conda
  - 2022se
categories:
  - diaries
date: 04-11-2023
---
# What I have done today

1. Eliminated the version incompatibility problem between CUDA and PyTorch.
	When I tried to run train processes in reproduction to [2022SE](https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/syen.12543), occurred erros:
	```
	[/home/junru/anaconda3/envs/rsfin/lib/python3.7/site-packages/torch/cuda/__init__.py:104](https://file+.vscode-resource.vscode-cdn.net/home/junru/anaconda3/envs/rsfin/lib/python3.7/site-packages/torch/cuda/__init__.py:104): UserWarning: NVIDIA GeForce RTX 4090 with CUDA capability sm_89 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37. If you want to use the NVIDIA GeForce RTX 4090 GPU with PyTorch, please check the instructions at [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)
	``` 
	CUDA version is a new one so I need to upgrade my torch version. But when I use the conda environment with python\=\=3.7, the default pytorch version will be 1.7.0. So It seems that the problem occurred somewhere else. The latest version of pytorch supporting python\=\=3.7 is pytorch 1.13.0,See [here](https://pytorch.org/blog/deprecation-cuda-python-support/) and [here](https://github.com/pytorch/vision#installation). So update with conda then.
1. Added voice player to Goldendict.
	- Install `mpv` for `translate-shell` by `sudo apt install mpv`. See *Audio Option* in `man trans` for more.
	- Add audio program in GoldenDict.
		- `Edit-Dictionaries-Programs-Add` 
		- Enable=yes; Type=Audio; Name=audio; trans -speak %GDWORD%;
	- Additionally, the commands for plain text is:
		- Trans to English as `trans  -no-ansi -e google -s auto -t en-US -show-original y -show-original-phonetics n -show-translation y  -show-translation-phonetics y -show-prompt-message y -show-languages n -show-original-dictionary y -show-dictionary y -show-alternatives y  “%GDWORD%”`
		- Trans to Chinese as `trans -e google -s auto -t zh-CN -show-original y -show-original-phonetics n -show-translation y -no-ansi -show-translation-phonetics n -show-prompt-message y -show-languages n -show-original-dictionary n -show-dictionary y -show-alternatives y “%GDWORD%”`

# What I need to do next

1. Update pytorch.[Done](https://zhangdeweb.site/2023/04/13/04-13-2023/)
2. Continue the reproduce.[Done](https://zhangdeweb.site/2023/04/18/04-18-2023/)



---
title: Day for outdoors
tags:
  - daily work
  - blog
categories:
  - diaries
date: 04-12-2023

---
# What I have done today

1. Went to LouGuanTai in ZhouZhi, Xian. Caught cicadas and play around. 
<div align=center>
<img src="/Pictures/1.jpeg" width="500" />
<img src="/Pictures/2.jpeg" width="500" />
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
      Fat flister beetle and  Cicadas had been caught
</div>
</div>



*Tips*: The method of add pictures into hexo blogs, see [here](https://hexo.io/zh-cn/docs/tag-plugins#%E5%B5%8C%E5%85%A5%E5%9B%BE%E7%89%87). If the format and notes of pictures need to set, it is have to use `html` grammar, see [more](https://blog.csdn.net/qq_32515081/article/details/124395842) . Pictures make websites start slowly, so use it carefully. Here is a simple example:
```
<div align=center>
<img src="/Pictures/*.jpeg" width="500" />
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
      Add Title here
</div>
</div>
```

2. IOS application `Working Copy` can edit files and sync with github. So that I can edit blogs on my iphone and deploy it using ssh remotely.


---
title: Goodbye, rubbish conda!
tags:
  - daily work
  - mamba
  - 2022se
categories:
  - diaries
date: 04-13-2023
---
# What I have done today

1. The previous error report of my reproducing CUDNN_STATUS_EXECUTION_FAILED maybe caused by the imcorrespond of version among cuda, cudnn and pytorch [see](https://blog.csdn.net/qq_40506723/article/details/124798992) and [see](https://blog.csdn.net/yu_xinli/article/details/127084720). Updating dependency with conda makes me crazy. It only runs at an extremely slow speed and I cannot change to a source makes me satisfy. I tried to uninstall all of conda and reinstall it but it won't help after trying for several times. I tried to install [mamba](https://github.com/mamba-org/mamba) followed by [guide](https://mamba.readthedocs.io/en/latest/installation.html).

2. After installed mamba, I installed conda environment with `mamba create env -f conda_environment.yml` after removing several packages' version info or it cannot be found in current sources. Dataset preparation runs well but train still have errors.
	- AttributeError: module 'torchvision.models' has no attribute 'mobilenet_v2'
		It caused by trochvision version is too low, [see](https://blog.51cto.com/u_12001271/5657216). So do `mamba update torchvision`
		- AttributeError: module 'torch.jit' has no attribute 'unused'
			It caused by corresponding problem between pytorch and torchvision, [see](https://blog.csdn.net/ZwaterZ/article/details/125268475). So do `mamba install torchvision==0.14.0 -c nvidia -c pytorch` and install failed. Caused by threads number limited, [see](https://blog.csdn.net/weixin_46779338/article/details/128319080). Use `ulimit -n 2048` and torchvision will be update correctly.
3. Check `mamba list | grep torch` and this will be shown:
	```
	WARNING conda.core.prefix_data:_load_site_packages(291): Problem reading non-conda package record at lib/python3.7/site-packages/certifi-2020.6.20-py3.7.egg-info/PKG-INFO. Please verify that you still need this, and if so, that this is still installed correctly. Reinstalling this package may help.
	 _pytorch_select 0.1    cpu_0 anaconda 
	 pytorch         1.13.1 py3.7_cuda11.7_cudnn8.5.0_0 pytorch 
	 pytorch-cpu     1.1.0  py37he1b5a44_0 conda-forge 
	 pytorch-cuda    11.7   h778d358_3 pytorch 
	 pytorch-mutex   1.0    cuda pytorch 
	 torchvision     0.14.1 py37_cu117 pytorch
	```
	And torch version in python had been 1.1.0. 

# What I need to do next

1. Change pytorch version to 1.13.0 and run train script.[Done](https://zhangdeweb.site/2023/04/14/04-14-2023/)

# What I want to do in future
- Learn about version corresponding or dependency among cuda, python or so on.

# What I want to tell myself
Calm down you clever. Just a dependency problem. Solve it quickly and move on!


---
title: It works! 
tags:
  - daily work
  - 2022se
categories:
  - diaries
date: 04-14-2023
---
# What I have done today

1. Ran the training script with a little change.
	- Most errors I met before caused by version corresponding among torch, torchvision, cuda, cudnn. Especially, remove `_pytorch.select` package in conda to use pytorch with gpu. Recreate environment of  'rsfin' followed by:
	```
	conda install pytorch==1.13.0 torchvision==0.14.0 torchaudio==0.13.0 pytorch-cuda=11.7 -c pytorch -c nvidia # to solve problem with some models not found in torchvision.  
	- mamba update ffmpeg # to solve problem with libopenh264.so.5 not found
	```
	Runs and errors occurred in line 23 `torchvision.transforms.RandomRotation(20, resample=Image.BILINEAR)`: 
	```
	 TypeError: __init__() got an unexpected keyword argument 'resample'
	```
	This caused by torchvision version changing. See `help(torchvision.transforms.RandomRotation)` in python and report: 
	```
	class RandomRotation(torch.nn.modules.module.Module)
	 |  RandomRotation(degrees, interpolation=<InterpolationMode.NEAREST: 'nearest'>, expand=False, center=None, fill=0)
	 |  
	 |  Rotate the image by angle.
	 |  If the image is torch Tensor, it is expected
	 |  to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.
	 |  
	 |  Args:
	 |      degrees (sequence or number): Range of degrees to select from.
	 |          If degrees is a number instead of sequence like (min, max), the range of degrees
	 |          will be (-degrees, +degrees).
	 |      interpolation (InterpolationMode): Desired interpolation enum defined by
	 |          :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``.
	 |          If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.
	 |          For backward compatibility integer values (e.g. ``PIL.Image[.Resampling].NEAREST``) are still accepted,
	 |          but deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
	 ... ...
	```
	Interpolation and resample are two kinds of method in image processing. The difference between them is that interpolation is one way to realize resampling for separate data, [see](https://www.jianshu.com/p/4b89d0d323e1). And the difference between NEAREST and BILINEAR is that BILINEAR is more delicate, [see](https://www.codenong.com/cs105851870/). So change the code to `torchvision.transforms.RandomRotation(20, interpolation=Image.BILINEAR)` and all will be fine.
2. Tried to run model test and error occurred in line 13 and 16. Variable `config.TESTING_MODEL_WEIGHTS.items()` do not have parameter `folder_name` and `mtype`. 
3. Went to the jobs fair and listened to the reports of Shaanxi insect society.
	 4 articles in CAS(Chinese Academy of Science) 1 = 35w/year
	  4 articles in CAS 2 = 25w/year
	  Few choice.
	 - Prof. Cao yanghui suggests that do not merge morphological traits dataset into molecular datasets because of the quantity difference and the unclear weighting rules. 

# What I need to do next

1. Solve the weights value problem. Read codes and it is easy.[Done](https://zhangdeweb.site/2023/04/15/04-15-2023/)

# What I want to do in future
- Systematic learn deep learning programming.

# What I want to tell myself
The basic problem in the whole 'version error' is that my GPU do not support torch version 1.5 and conda cannot install all dependency they listed. So I have to change some packages in the dependency. The newer package I use have some change in grammar. Luckily, I found out where the problem is and solved it at last. 


---
title: Why there are three best? 
tags:
  - daily work
  - 2022se
categories:
  - diaries
date: 04-15-2023
---
# What I have done today

1. Checked the errors.
    Changed `config.py` because I had reorganize data. (Or there would be errors same to editing with a wrong folder name.)
    
	```
	# TESTING_DATASET_NAME = 'test_data'
	TESTING_DATASET_NAME = 'datasets/test_data'
	```
	And returned path error: `FileNotFoundError: [Errno 2] File /mnt/data/trait/reference/2022se/insects-recognition-main/datasets/datasets/test_data/df_img_meta.csvdoes not exist`.

	There are two `datasets` directories in the path.

	Tried to use absolute path in both `DATASETS_LIST` and `TESTING_DATASET_NAME` in `config.py` and the path error solved. 
	*Significantly, `model_test.py` needs directory `weights` locate at object-home-path and using relative path in `config.py`.*
	
2. New error occurred in `test_model` function with `AssertionError:  `.`test_model` was import from `model_test.py` and error occurred at line 180 which is caused by `assert` function. 
      Error message:
	```
	--------------------------------------------------------------------------- 
	AssertionError Traceback (most recent call last) 
	in 
	18 print(config.TESTING_DATASET_NAME) 
	19 test_model(model_name=config.TESTING_MODEL_NAME, dataset_name=config.TESTING_DATASET_NAME,
---> 20 folder_to_evaluate=folder_name, model_type=mtype) 
	 21 if config.TESTING_INTERPRETABLE_PLOTS: 
	 22 make_interpretable_plots(model_name=config.TESTING_MODEL_NAME,
   
   /mnt/data/trait/reference/2022se/insects-recognition-main/src/models_test.py
	 in 
	 test_model(model_name, dataset_name, folder_to_evaluate, model_type) 
	 178 # Формирование табличного отчета по качеству классфикации 
	 179 # Для объективной оценки испольузем только лучшую эпоху по валидации. 
---> 180 assert len(reports_list) == 1 
	181 report_dict = reports_list[0] 
	182 df_detailed_report = pd.DataFrame([]) AssertionError: 
	```
	
	The comments in line 178 and 179 said that we need a best something, namely the length of `reprots_list` must be 1 or occurred this error.

	Check variable `reports_list` in `models_test.py`. 
	```
	EVAL_DICT = {'device': DEVICE,
	'weights_folder': weights_folder,
	'test_loader': test_data_loader,
	'model': nnet,
	'criterion': torch.nn.CrossEntropyLoss(),
	'target_names': list(TRAIN_DATASET_KWARGS['class_dict'].keys()),
	'class_dict': CLASS_DICT,
	'data_hash': train_data_hash,
	'external_data_class_dict': None,
	
	reports_list = model_evaluate(EVAL_DICT)
	```
	 Check function `model_evaluate` in `./utils/model_test_utils.py`.
	```
	def model_evaluate(evaluate_dict):
	weights_folder = evaluate_dict['weights_folder']
	weights_list = [os.path.join(weights_folder, x) for x in os.listdir(weights_folder) if '.pth' in x]
	epoch_dict = dict([(int(x.split('.')[0].split('_')[-1]), x) for x in weights_list])
	sorted_epochs = sorted(epoch_dict)
	reports_list = []
	for epoch in tqdm.tqdm(sorted_epochs):
		weights_path = epoch_dict[epoch]
		print('Epoch: ', epoch)
		print('Weights path: ', weights_path)
		if evaluate_dict['external_data_class_dict']:
			report_dict = eval_epoch_on_external_data(weights_path, evaluate_dict)
		else:
			report_dict = eval_epoch(weights_path, evaluate_dict)
		report_dict.update({'epoch': epoch})
		reports_list.append(report_dict)
	return reports_list
	```
	Check the length of `reports_list` in `for` by adding `print(len(reports_list))` and found that the length grew up to 3 from 1 caused by `reports_list.append(report_dict)`. 
# What I need to do next

1. Find out how `append` works and why use it. How to make it correct. 



---
title: Trying to make plots.
tags:
  - daily work
  - 2022se
categories:
  - diaries
date: 04-16-2023 
---
# What I have done today

1. An easiest way to solve reports_list length error is annotate the assert functions. So I annotate assert functions limiting reports_list (and weights_list) length in test_model (and make_interpretable_plots) function on model_test.py line 180 (and 602). New problem is that there are only two empty result folders which should be three folders with result plots. 
	The function creating result folders is `make_interpretable_plots` defining in `model_test.py`. But I do not find which statement creating the folder. I checked the variables and `weights_list` are 4 because there are four files in directory of weights_folder. `weights_path` is ok because it is set to `weights_list[0]` by the authors.
	
  2. I checked the next variable occurred, `manual_images`, defined as a parameter in function `make_interpretable_plots`. It set to a list of pictures named by SHA. This parameter was set manually in the `model_test.ipynb` which the pictures I do not have. So I annotated the contents in the variable `manual_images` and I got the testing for my own testing datasets. This process may be last for half an hour to several hours. Previous trying make mistakes in manual_images of make_interpretable_plots function so that it did not running correctly. Now it runs completely and results plots are shown.

# What I need to do next

1. When the process is finished, keep checking this error. Up to now, there are a few questions about this error in my mind. 
	1. The assert function limit something must be only one and they are not.
	2. What is meaning of statements followed by asserting manual_images is a list and why. 
	3. Which function create folders in results?
2. How to evaluate the identification and make it useful for me?
3. Report my work to my tutor.


---
title: High-resolution screen with larger fonts.
tags:
  - daily work
  - 2022se
  - i3wm
  - rofi
categories:
  - diaries
date: 04-17-2023
---
# What I have done today

1. Previous application launcher process, `dmenu`, is not really good for me. It is difficultly to configure so I decide to turn to [`rofi`](https://github.com/davatorium/rofi), a modern application launcher and windows switcher to replace `dmenu`. 
	1. Installation with `sudo apt install rofi` and remove `dmenu`.
	2. Download themes for `rofi` from [here](https://github.com/newmanls/rofi-themes-collection). More about [usage](https://github.com/davatorium/rofi/wiki/Themes) and [rofi config](https://github.com/davatorium/rofi/blob/next/CONFIG.md). Followed by the documents, move theme files to `~/.config/rofi/themes` and preview themes by running `rofi -modi run -show run` and select `rofi-theme-selector`. Set default theme by editing `rofi` config file, which created by command `rofi -dump-config > ~/.config/rofi/config.rasi`, to add `@theme "MyTheme"` in the end following `configuration {}`. Use `rofi -help`  to check configuration file path. Fonts and other settings can be edit in theme files.
	3. `Rofi` has several built-in modes implementing common use cases. Here is the differences of commonly used ones.
		-   **run**: launch applications from $PATH, with option to launch in terminal.
		-   **drun**: launch applications based on desktop files. It tries to be compliant to the XDG standard.
		-   **window**: Switch between windows on an EWMH compatible window manager.
		-   **ssh**: Connect to a remote host via ssh.
		-   **filebrowser**: A basic file-browser for opening files.
	4. Configure `i3wm` to change application launcher.
		```
		# annotate dmenu command
		# bindsym $mod+d exec --no-startup-id dmenu_run -fn DejaVu-25 
		# A more modern dmenu replacement is rofi:
		bindsym $mod+d exec --no-startup-id "rofi -modi drun,run -show drun "
		bindsym $mod+w exec --no-startup-id "rofi -modi drun,run,window -show window 

		# remember to remove conflicting shortcuts
		```
	5. Modes `drun` launch applications based on desktop files. The way to add application to the menu is that add `.desktop` file in directory `/usr/share/applications/`. An easy way for adding is copy another file and edit the appropriate lines for name, exec, and icon. It is recommended to use full path. It seems like relate to `xdg`, so may be `man xdg-open`, `man xdg-settings` can tell more.
2. Training models with my own pictures dataset from Dr. Liang Zonglei. (I used full pictures include several structures in this time.)
	1. Edit dataset path and re-organize files in dataset folder. *Remember: **DO NOT** only use number as file name or as the start of file name, or error occur with function `len()` during training.* 
	2. Prepare dataset and train. All will be fine. When train is done, change `TESTING_MODEL_WEIGHTS` to current folder name.
	3. Testing datasets and new error occurred.
		```
		RuntimeError Traceback (most recent call last) in 
		18 print(config.TESTING_DATASET_NAME) 
		19 test_model(model_name=config.TESTING_MODEL_NAME, dataset_name=config.TESTING_DATASET_NAME, 
		---> 20 folder_to_evaluate=folder_name, model_type=mtype) 
		21 if config.TESTING_INTERPRETABLE_PLOTS:
		22 make_interpretable_plots(model_name=config.TESTING_MODEL_NAME, 
		/mnt/data/trait/data/test_se/src/models_test.py in test_model(model_name, dataset_name, folder_to_evaluate, model_type) 
		174 'external_data_class_dict': None, 175 } 
		--> 176 reports_list = model_evaluate(EVAL_DICT) 
		177 
		178 # Формирование табличного отчета по качеству классфикации 
		/mnt/data/trait/data/test_se/src/utils/model_test_utils.py in model_evaluate(evaluate_dict) 
		163 report_dict = eval_epoch_on_external_data(weights_path, evaluate_dict) 
		164 else: 
		--> 165 report_dict = eval_epoch(weights_path, evaluate_dict) 
		166 print('hahahahahahahahahahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh') 
		167 print(reports_list)
		/mnt/data/trait/data/test_se/src/utils/model_test_utils.py in eval_epoch(weights_path, evaluate_dict, plot_roc_curve) 
		51 model.cuda() 
		52 
		---> 53 model.load_state_dict(torch.load(weights_path)) 
		54 model.eval() 
		55 y_true, y_pred = [], [] 
		~/mambaforge-pypy3/envs/rsfin/lib/python3.7/site-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict) 
		1666 if len(error_msgs) > 0: 
		1667 raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format( 
		-> 1668 self.__class__.__name__, "\n\t".join(error_msgs))) 
		1669 return _IncompatibleKeys(missing_keys, unexpected_keys) 
		1670 
		RuntimeError: Error(s) in loading state_dict for MobileNetV2: 
		size mismatch for classifier.1.weight: copying a param with shape torch.Size([32, 1280]) from checkpoint, the shape in current model is torch.Size([5, 1280]). 
		size mismatch for classifier.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([5]).
		```

# What I need to do next

1. Keep debugging. [Done](https://zhangdeweb.site/2023/04/18/04-18-2023/)

# What I want to tell myself
Today I find that the thing I did recently is debugging for codes. It does not have much  fun to me. When I have done with it, I should find out a scientific question and focus on natural history.


---
title: Running complete. Now, explain it!
tags:
  - daily work
  - 2022se
categories:
  - diaries
date: 04-18-2023 
---
# What I have done today

1. The error occurred yesterday caused by using an incomplete model weight file, [see](https://zhuanlan.zhihu.com/p/340908578). Re-trained model and used new directory path. Running completed.  
2. The identify result is not pretty good. Because I did not organize these pictures in class carefully and I used the full picture including different structures. This time, I tried to use the results of [04.07](https://zhangdeweb.site/2023/04/07/04-07-2023/) which includes pictures of separate structures.  
	1. Copy result folders to the datasets directory and rename it to 'raw'. Remove files that do not need. 
	2. Organize files using [a shell-script](test.txt).
	3. Start running that series of programs and get results.

# What I need to do next

1. Read the article again and evaluate the results.[Done](https://zhangdeweb.site/2023/04/19/04-19-2023/)



---
title: Ready for group meeting?
tags:
  - daily work
  - 2022se
  - vim
  - rofi
  - unicode
categories:
  - diaries
date: 04-19-2023 
---
# What I have done today

1. Tried to scale up font size and windows in i3wm followed [this](https://askubuntu.com/questions/1433238/hidpi-screen-problem-in-i3wm) and found that it is not easy.
2. Evaluated the results, shown in the [article](https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/syen.12543).
	> Dataset was split into three consequent sub- samples: training, validation and testing – 70%, 15% and 15%. 
	> ... ...
	> To measure a model quality, several metrics were used: averaged by class and weighted by a value of class instances types of precision, recall, F-score and top-1 error rate. The precision is a ratio of true- positive classification and the sum of true-positive and false-positive classification. The recall is a ratio of true-positive classification and the sum of true-positive and false-negative classification. The F-score is a harmonic mean of precision and recall metrics.
	> ... ...
	> For LIME we set ‘top_labels’ to 1 to produce explanations only for the class with the highest confidence value, ‘num_features’ to 5 to limit the number of features that are presented in an explana- tion. The green areas are treated in favour of the true class, and the red ones are treated as the regions against the true class. For Grad- CAM, we choose the last layer visualization because it is a layer that accumulates more primitive features that are extracted from previous layers. For RISE the number of masks ‘N’, the size of the smaller square binary masks ‘s’ and the probability of each pixel in the smaller masks ‘p’ were empirically set to 1000, 8 and 0.2, respectively.
	> ... ...
	> LIME and Grad-CAM algorithms were much more likely to show the expected areas of interest within which the recognized object was located. Some of the visualization results obtained with RISE focused in great detail on the image of the area within the specimen.
  Namely, I should check those value and LIME results. Top-1 error rate about means mismatch rate, [see](https://www.cnblogs.com/zyr001/p/14544031.html). 

 3. Make PPT for group meeting tomorrow.

# What I want to tell myself
- For those application complied locally which had been installed in `*/bin/`, the source file can be deleted.
- For inserting digraph or unicode symbols in neovim, follow [here](https://alpha2phi.medium.com/neovim-101-digraphs-icons-and-symbols-8bceee7817b7). Type CTRL-Q in insert mode to enter visual mode and type U or u following unicodes and then type enter or space to quit the mode and the symbol will be typed in. Additional, the rofi can help type unicode symbols by install [rofimoji](https://github.com/fdw/rofimoji) and set shortcut in i3wm



---
title: En attendant Godot
tags:
  - daily work
categories:
  - diaries
date: 04-20-2023
---
# What I have done today

1. Waited for group meeting and meeting had been canceled. Maked PPT.

# What I need to do next

1. Read articles and prepare for PhD object.


---
title: Upgrade WiFi connection to AP mode
tags:
  - daily work
  - latex
  - zotero
  - csl
  - router
categories:
  - diaries
date: 04-21-2023
---
# What I have done today

1. Installed [Tex Live for unix](https://www.tug.org/texlive/quickinstall.html) but there is no package management good enough for ubuntu. `tlmgr` cannot be found in `sudo`, [see](https://tex.stackexchange.com/questions/203874/sudo-does-not-find-tlmgr).
2. Installed [zotero] for inserting citations in `.docx` files. The method of custom reference format can be found [here](https://blog.csdn.net/baidu_39389949/article/details/115867377), more about [CSL](https://docs.citationstyles.org/en/stable/) and [a visualize tool](https://editor.citationstyles.org/visualEditor/).
3. Installed a new WiFi router with AP mod but it cannot start ap mod successfully. So I still use dhcp. Additionally, the gateway cannot be same with ip in LAN masknet, remember to change one.
4. Ready for writing. 

# What I need to do next

1. Search articles totally.


---
title: Using WiFi router in ap mode with R6S 
tags:
  - daily work
  - router
  - latex
  - mount
categories:
  - diaries
date: 04-22-2023
---
# What I have done today

1. Configured router with ap mode but no remote connection for its best performance. 
	1. Use TpLink AX3000 XDR3010 which support ap mode to connect to R6S. R6S has a powerful CPU and TpLink has a higher speed than the previous wireless router, Oray X5. Compared with routing mode, ap mode make all devices under a same local network without creating a new subnet, [see](https://zhuanlan.zhihu.com/p/349604997). Otherwise, it may improve performance by reducing forward times and letting the more powerful CPU of R6S deal with events. Since then, compared with previous one, the new scheme can improve Wi-FI speed and CPU efficiency in only one LAN.  
	2. Ap mode of TpLink Wi-Fi router can be open after setting `network setting - wired - ipv4 - shared to other computer` in LAN network controller of R6S.
	3. Configure DHCP for R6S, followed [here](http://linuxfordevices.com/tutorials/ubuntu/dhcp-server-on-ubuntu) and [a Chinese guide](https://www.codenong.com/cs105867978) and [another one](https://blog.csdn.net/weixin_52365243/article/details/127344447). Fixed IP address should **NOT** be in DHCP and remember to cancel the annotation of `authoritative`. But it still cannot check which ip has been used and manage them in an easy way. Maybe there is a application can help me.
	4. Because of IP address changing, I need to reset my NAS auto-mounting by `sudo vim /etc/fstab` and `sudo mount -a`. 
	5. Installed Oray pgyvpn in docker but because of using subnet it is not better than connecting Oray X5. IPV6 is not a good choice, either. 
2. Solved the problem of Latex package manager `tlmgr` cannot be found in `sudo`, followed by [here](https://www.douban.com/note/557555838/?_i=2084163zFaZOiT,2166830zFaZOiT). Run `sudo visudo` and add the `/bin` path into `Defaults secure_path`.


# What I want to do in future
- Connect Oray X5. Try to find out how to manage IPs in R6S.ubuntu. [Done](https://zhangdeweb.site/2023/04/23/04-23-2023/)
- The connection in safari of iPhone is very slow. Find out the reason. [Done](https://zhangdeweb.site/2023/04/23/04-23-2023/)
- Learn more about the basic of network technology for a better using of R6S.
- Install fonts from MacOS and Windows to ubuntu for Latex.



---
title: Professional things should be left to professionals.
tags:
  - daily work
  - router
  - openwrt
  - dns
  - LAN
categories:
  - diaries
date: 04-23-2023
---
# What I have done today

1. Problem of Safari network connection had been solved by changing DNS service. It should not be `8.8.8.8` or `114.114.114.114`. Deleted options related in DHCP configuration which in `/etc/dhcp/dhcpd.conf`. 
	- *Additionally, DNS configure file can be found [here](https://blog.csdn.net/OceanWaves1993/article/details/128217710). Edit `/etc/systemd/resolved.conf`, run `systemctl restart systemd-resolved.service` and add link by `sudo ln -s /run/systemd/resolve/resolv.conf /etc/`*.
2. Installed [Friendlywrt](https://wiki.friendlyelec.com/wiki/index.php/How_to_Build_FriendlyWrt), a variant of [openwrt](https://openwrt.org) on R6S, to instead of Friendlyelec-ubuntu. Considering the specialization and complexity of configuration, the operating system for router is better than Ubuntu. Especially, the setting of dhcp or slaac assignation of ipv6 address in ubuntu needs configure network interfaces (more info see `man interfaces`) but the default network configuration is using `network-manager`. Changing `interfaces` config file will cover settings in `network-manager` and I do not know how to combine them. The interfaces cannot be configured for ap router easily for me and the Ubuntu system takes more spaces and ram. Besides, I do not know how to check which ips I have used in Ubuntu. Considering I may have more complex needs in the future, compared to edit every thing from zero, I prefer to use configure-completed and powerful `openwrt`.
    1. Friendlywrt operating system installation is very easy by following [their wiki](https://wiki.friendlyelec.com/wiki/index.php/NanoPi_R6S/zh). 
    2. Use tower for network sharing to R6S in order to install python and pip by `opkg update && opkg install python3 && wget <get-pip3.py> && python get-pip3.py` and then use `pip install srun-cli` to install the campus network auto-authentication program.
    3. Maintain the LAN topology and tplink wireless router sets to ap mode.
    4. Reset nas [auto mount](http://zhangdeweb.site/2023/04/22/04-22-2023) in `tower.ubuntu`.

# What I need to do next

1. Set ip address, ipv6 and other settings in Friendlywrt. Be familiar with openwrt/Friendlywrt system. [Done](https://zhangdeweb.site/2023/04/24/04-24-2023/)
2. Check the previous todo list and add tags for them. [Done](https://zhangdeweb.site/2023/04/23/04-23-2023/)
    *The speed of network is not slow. Maybe the speed of campus network is erratic.*




---
title: Hello cool ipv6 and goodbye.
tags:
  - daily work
  - ipv6
  - ssh
  - router
categories:
  - diaries
date: 04-24-2023
---
# What I have done today

1. Set another IP for R6S.openwrt.LAN by following [their wiki](https://wiki.friendlyelec.com/wiki/index.php/NanoPi_R6S/zh#.E6.9B.B4.E6.94.B9LAN.E5.8F.A3.E7.9A.84IP.E5.9C.B0.E5.9D.80). 
2. SSH Pub-key authentication. It is more safety and convenient because it does not need a password every time to log in.
	1. Use `ssh-keygen && ssh-copy-id <remote server ip>` to add pub keys into server.
	2. Edit local `~/.ssh/config` file, to set a common name, with:
		```
		Host <server name>
			HostName <server ip>
			User <user name>
		```
	3. If pub key authentication cannot success, try to config file `/etc/ssh/ssh_config` and set `StrictModes` option to "no", more about see `man sshd` and `man ssh_config`.
3. Ipv6 configuration in R6S with openwrt followed by [here](https://zhuanlan.zhihu.com/p/492774540). Sometime R6S cannot get an ipv6 address from campus net, maybe because of a network error. Reconnect the net cords and wait for a minutes, it will be fine. After the whole configuring, I can visit ipv6 sites in my tower device (connected with R6S by wired LAN). But it does not work on mac which is connected with R6S by wireless LAN. Besides, I cannot visit my ipv6 address outside my LAN because of the nat6. The reason of using nat6 is I can get only one address, not a sub-net, from campus network so I have to use nat6 to forwarding address to other devices.
	<div align=center>
	<img src="/Pictures/ipv6speed.jpg" width="500" />
	<br>
	    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
	    display: inline-block;
	    color: #999;
	    padding: 2px;">
	      It's so cool! But it is sadly that I cannot visit my ipv6 address via WAN.
	</div>
	</div>

# What I need to do next

1. Organize my to-do list for my PhD object.[Done](https://zhangdeweb.site/2023/04/25/04-25-2023/)

# What I want to do in future
- Solved the remote access issue. Something may help here, such as [nat64 in openwrt](https://openwrt.org/docs/guide-user/network/ipv6/nat64), and [others](https://blog.csdn.net/qq_29688717/article/details/129506914), but it needs more settings to complete.

# What I want to tell myself
I think it is time to give up tossing these messes for now. I can just stop ipv6 and use a dumb methods, using Oray X5, because what i need is remote access, not ipv6. Otherwise, configure the network setting cost my too many time. I have lots of other more important business to do.


---
title: Clipboard is a fantastic thing.
tags:
  - daily work
  - polybar
  - rofi
  - clipboard
  - srun-cli
categories:
  - diaries
date: 04-25-2023
---
# What I have done today

1. Organized to-do list. I have tried to add a to-do list plugin on desktop environment, by using polybar module to run `alacritty -e vim <todo.md>`. I added it by learning the other modules added in polybar.
	1. I am using the `polybar` with theme forest which is from [polybar-themes](https://github.com/adi1090x/polybar-themes) package in github. `Polybar` starts in `i3wm` and the startup file, `launch.sh`, can be found in `~/.config/polybar/launch.sh`.
		```
		#!/usr/bin/env bash
		
		dir="$HOME/.config/polybar"
		themes=(`ls --hide="launch.sh" $dir`)
		
		launch_bar() {
			... ...
				polybar -q main -c "$dir/$style/config.ini" &	
			... ...
		}
		
		if [[ "$1" == "--material" ]]; then
			style="material"
			launch_bar

		... ...
		```
	2. Following the script, I check the file `~/.config/polybar/forest/config.ini` because this is the theme I am using. The additional modules are included in `user_modules.ini` and  added by variable `modules-left/center/right`. 
	3. Add module `todo` in `user_modules.ini` by copying and editing the `module/launcher`. 
		```
		[module/todo]
		type = custom/text
		content = ✔
		content-foreground = ${color.yellow}
		click-left = alacritty -e vim ~/blog/curiosusJR.github.io/source/_posts/00-TODO-LIST.md
		```
		
	4. Add `todo` module into `config.ini` by changing it to:  `modules-center=date sep todo`
	5. Restart `i3wm`.
		
2. Installed an clipboard helper, [greenclip](https://github.com/erebe/greenclip), as a plugin of `rofi`. Added it into `i3wm` keyboard shortcuts. 
	1. After installing the static binary file into `~/.local/bin`, add execution permission with `chmod +x` and add auto-startup process in i3/config with adding a line of `exec_always ~/.local/bin/greenclip daemon`. *Remember that do not use `--no-startup-id`.* 
	2. Add shortcuts of auto-paste (see [here](https://github.com/erebe/greenclip/issues/27)) in i3/config. 
		`bindsym Ctrl+v exec--no-startup-id rofi -modi "clipboard:greenclipprint" -show clipboard -run-command '{cmd}' && sleep 0.2 && xdotool type $(xclip -o -selection clipboard)`
	3. In the way showed above, the space cannot be paste successfully. It can be solved by [here](https://github.com/jordansissel/xdotool/issues/119), just add `"` beside `$(xclip -o -selection clipboard)`.
	4. The paste action cannot be canceled by default. It had been discussed  [here](https://github.com/erebe/greenclip/issues/27) but all of them are not perfect. **So I still use methods above and copy a space anytime, thus when I cancel a copy and it will only paste a space there.** The most useful method (but still with bugs) seems like using a script create in `~/.local/bin/paste-modi.sh`
		```
		greenclip print $@
		coproc (xdotool key --clearmodifiers "ctrl+v" &)
		exit 0
		```
		and run it with `rofi -modi "paste:/home/junru/.local/bin/paste-modi.sh" -show paste`
3. Network broken retry. 
	1. Because campus network login status will be refreshed every 24 hours or by some unknown reasons, I need to re-login when it logouts. 
	2. Under the campus network, command `ping` can always success whether it has been login or not, so I have to use `curl` to get http code for checking network connection. [Here](https://blog.csdn.net/weixin_46686835/article/details/113761418) is more info about using  `curl` to get http codes and [here](https://blog.csdn.net/qq_50685659/article/details/126233902) is more info about http codes.
	3.  In order to eliminate the impact of websites, I want to test a few sites. So [here](https://blog.csdn.net/helloxiaozhe/article/details/118755685) is the  way to  go through the groups.
	4. There are many campus network login tools on github or other repositories, [such as](https://github.com/ehaut/srun3k-client-cli). 
	    By sum up, create auto-login script as:
		```
		#! /bin/bash
		http_list=( www.baidu.com www.nwafu.edu.cn );
		http_code=404;
		error_times=0;
		for i in ${http_list[@]}
		do
			http_code=`curl -o /dev/null -s -w %{http_code} $i`;
			if [[ ${http_code%??} != 2 && ${http_code%??} != 3 ]]
			then
				((error_times=error_times+1));
			fi
		done;
		if [ $error_times != 0 ]
		then
			srun-cli ;
		fi
		``` 
	5. Auto-run the script with `crontab` in ubuntu or  openwrt.
		```
		$ crontab -e
		#crontab
		* * * * * sh path/to/auto-relogin

		$ /etc/init.d/cron restart
		
		```

# What I want to do in future
- [ ] It would be even better if the to-do list could pop up in a drop-down menu. I can create an object in github. Referring rofi source code and reading more documents will help me.
- [ ] The paste action cannot be canceled by default. It had been discussed  [here](https://github.com/erebe/greenclip/issues/27) but all of them are not perfect.


---
title: I remember that I have 2 ethernet card.
tags:
  - daily work
  - ipv6
categories:
  - diaries
date: 04-26-2023
---
# What I have done today

1. Improved the [network-broken-retry-script](network-broken-retry.txt). Something about [reading from files](https://blog.csdn.net/yogima/article/details/128833660) and [checking numbers of lines in file](https://blog.csdn.net/pearl8899/article/details/108522763). The websites for checking network connection are included in `/root/.Network_Connection_Test_List`. Log file will be written in `/root/` when all the test sites are inaccessible and re-try for login.
2. Using systemd.network to config ethernet card by checking `man systemd.network`. 

# What I want to do in future
- Enable ipv4 in enp3s0 and disable ipv4 in enp0s31f6. Disable ipv6 in enp3s0 and enable ipv6 in enp0s31f6. 



---
title: The final work was done on the eve of holiday.
tags:
  - daily work
  - ipv6
  - ddns
categories:
  - diaries
date: 04-27-2023
---
# What I have done today

1. Completed ipv6 setting on R6S, followed [here]( https://blog.csdn.net/LawssssCat/article/details/104443072). 
	1. Use `socat` followed [here](https://www.right.com.cn/forum/forum.php?mod=viewthread&tid=4129434&page=1#pid11351439) for visiting LAN from ipv6-WAN. (This might be nat64.) 
		**It must be turned off the VPN or ip will be changed.** 
	2. At the last, set a firewall in openwrt. Ipv6 WAN connection from TCP/UDP will be forwarded to selected port in selected LAN host (refer other default setting). Now, I can visit local servers using \[ipv6\]:\<port\> address. 
	3. The ipv6 address can be changed when I restart my network server or reboot. So I need a DDNS service and a new domain name. Buy one from [aliyun](https://wanwang.aliyun.com/?spm=5176.21213303.1158081.1.590d53c9p19xoF&scm=20140722.S_card@@%E5%95%86%E5%93%81@@212429.S_card0.ID_card@@%E5%95%86%E5%93%81@@212429-RL_%E5%9F%9F%E5%90%8D%E6%B3%A8%E5%86%8C-OR_ser-V_2-P0_0) and set dns/ddns services with [DDNS](https://github.com/NewFuture/DDNS) scripts found at GitHub. Use `crontab` for automatic updating.

2. Add a new testing user on tower-server for others to link to later by `sudo adduser`.
# What I want to tell myself

A few days recently, I focused on my LAN and its remote connection. It takes some time for solving various issues I did not familiar with before. The remaining im-perfections are my tower server security. I do not know if current solution is secure enough. But I think it is securely enough because of campus networks and I do not have many valuable things.

It is really time to do something serious. I must devote all my energy to my PhD proposal,

when I come back from vacation! 😜


---
title: Ready for my report. 
tags:
  - daily work
  - Ph.D
  - proposal
categories:
  - diaries
date: 05-04-2023
---
# What I have done today

1. Preliminary organized my thinking of the proposal report.

# What I want to tell myself
I have come back from my vocation. Write my reports as draft in markdown.

In my zsh configure, the git-information is shown by p10k plugin in zim. It can be found that the signs meaning in [their github  page](https://github.com/romkatv/powerlevel10k/tree/master/gitstatus). Git stash is a temporary action, [more about](https://www.cnblogs.com/tocy/p/git-stash-reference.html).

 In following period of time, my work will be focused on writing my proposal report. For the integrity of the idea, my daily work will be concentrated in the draft of the report, rather than the separate log.


---
title: KataGo and sabaki on tower 
tags:
  - daily work
  - Go 
  - katago
  - sabaki
categories:
  - diaries
date: 05-16-2023
---
# What I have done today

1. Installed sabaki, a desktop app for go game. Install the `.AppImage` file from [its github](https://github.com/SabakiHQ/Sabaki/releases/tag/v0.52.2) and create a desktop file in `/usr/local/applications/` for it.
2. Installl the latest version from [github](https://github.com/SabakiHQ/Sabaki/releases/tag/v0.52.2). I had installed the TensorRT version followed:
 <https://github.com/lightvector/KataGo#opencl-vs-cuda-vs-tensorrt-vs-eigen>. (zip installation will report errors that tensorrt version mismatch. Build from source will solve this issue, [see](https://github.com/lightvector/KataGo/issues/770) )
	1. So I need to install `tensorrt 8.5` using `.deb` package first followed: <https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-853/quick-start-guide/index.html#installing-debian>. *Remember to install the CUDA 11.8 for this which means change the link of `/usr/local/cuda`. Use `stat /usr/local/cudd` to check which version it links to.* 
	2. Use `sudo apt-cache madison tensorrt` to check the installable version and select the correct one to install. If it cannot install its depends, trying to install depends on `/var/nv-tensorrt-local-repo-*/*.dev`. 
	3. After installing tensorrt, reboot.  
	4. Build from source, followed by [here](https://github.com/lightvector/KataGo/blob/master/Compiling.md). Installation locate at `~/.opt/katago`.
	5. Install the larger (40 block network) network [model](https://github.com/lightvector/KataGo/releases/download/v1.4.5/g170-b40c256x2-s5095420928-d1229425124.bin.gz) from <https://github.com/lightvector/KataGo/releases/tag/v1.4.5>.
	6. [Usage](https://github.com/lightvector/KataGo#how-to-use). 
	7. Add katago gtp -model <> -config <> in sabaki. 

3. Solved the issue that it gets stuck when copy contents from alacritty to chrome by re-build alacritty and use the whole directory to startup alacritty. Moved it to `/opt/alacritty` and link it to `/usr/local/bin/alacritty`.
4. Added fonts from macos and windows11 in ubuntu. Copy font files `.ttf` to `/usr/local/share/fonts/custom` and set code `744` in chmod. And then `sudo mkfontscale && sudo mkfontdir && sudo fc-cache -fv`.


---
title: Insect phylogenetic analysis using image clustering method
tags:
  - daily work
  - phylogeny
  - image clustering
  - reproducification
  - kailan
categories:
  - diaries
date: 05-22-2023
---
# What I have done today

1. Reproduced the work of [Tao and Sun (2022)](https://www.sciencedirect.com/science/article/pii/S246826592200107X?via%3Dihub) using datasets from  [2022SE](https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/syen.12543). 
	1. Download the python 3.8.5 script in supplementary data. The directory should be organized in the way below:
	```
		.
		├── dataset
		│  ├── ...
		├── Learn_pld_376_Supplement 3. Image Cluster Score_mmc3.py
		├── Learn_pld_376_Supplement_2_Image_Clustering_mmc2.py
		├── train
		└── validation
	```
	2. Install the dependence. Use conda for python 3.8.5 installation. Use pip for tensorflow installation.
	3. Change the path and modelSpList for your data. Change the num_classes for your own data. For checking the image file is broken or not, use `ffmpeg` to change the format of images in your dataset.
	4. The script I have edited for my using and adding some annotation can be found [here](Learn_pld_376_Supplement_2_Image_Clustering_mmc2.py) .
	5. When the clustering done, the directory should be added some files like this:
		```
		.
		├── dataset
		│  ├── ...
		├── fine-tune-inceptionResnetV2N.h5
		├── fine-tune-resnet50NN.h5
		├── Learn_pld_376_Supplement 3. Image Cluster Score_mmc3.py
		├── Learn_pld_376_Supplement_2_Image_Clustering_mmc2.py
		├── randomTrees38.nexus
		├── train
		│  ├── ...
		└── validation
		   ├── ...
		```
	6. The file named `randomTrees38.nexus` is 1000 random distance-based trees using inceptionRestnetV2 model. The number and model can be changed in the python script easily after reading it. 
	7. Calculate the consensus tree using [Paup 4.0](http://phylosolutions.com/paup-test/) , which has a detailed [manual](http://phylosolutions.com/paup-documentation/paupmanual.pdf). Simply put, the script of Paup below can calculate the consensus tree. Use `help <command>` in Paup for more info.
		```
		Execute ./randomTree38.nexus
		contree /majrule=yes percent=50 LE50=yes treefile=consensus_1000_inceptionResnetV2.nexus;
		```
# What I need to do next

1. Change number and models for testing and retry.
2. Check the plots of epoch accuracy for the model. Check the topology of consensus tree and the SSI value using the script in Supplement 3.
3. Output the trait matrix if possible.



---
title: Trait extraction and output in image clustering.
tags:
  - daily work
  - image clustering
  - kailan
  - trait extraction
  - continuous trait matrix
categories:
  - diaries
date: 05-23-2023
---
# What I have done today

1. The dataset I used was wrong. It only contain the outgroups so I re-downloaded dataset with `zenodo_get` from <https://zenodo.org/record/5866217#.ZGxPMdJBwUE>. 
2. Changed `batch_size=30, epochs=500` in model settings, `voteTimes=500` in distance calculation, `treeNum=10000` in random tree generation and re-run the script. Consensus tree was calculated in the same way to yesterday. Checked the results in Figtree and found that species from same genus did not get together and the results of two runs with different paramerters were significantly different. I should use whole dataset to try again and use different parameters to find out the if it will convergence to a situation or not.
3. Image features were extracted by function `get_image_feature` in supplementary file 2 with [Keras](https://keras.io/).  There is a global variable `picDic` recorded all features of pictures randomly selected in all species in `get_image_feature` function. After running the whole script, I can output `picDic` to a `.csv` file for getting the raw feature data. The feature data is a 1 d array contain normalized RGB information, which means it does not contain location correlation information. **This part can be further optimized.** Output `picDic` to `.csv` used the script below:
	```
	for i in picDic.keys():
	    f=open("../output/"+i.split('/')[1]+".csv", "a", encoding="utf-8")
	    np.savetxt("./output/out_"+i+".csv", picDic[i], fmt='%f', delimiter=',', newline=' ' ,encoding='utf-8')
	```
	And then I can get 813 files which is the length of `picDic` and every file contain 1536 continuous features.

# What I need to do next

 - [ ] Use whole dataset with different settings and model to conduct trees and check the topology. Current (newer one) parameters shows a worse result in the curve plots. Try more.
 - [ ] RevBayes and Beast can deal with continuous traits and mrbayes cannot. Try to build trees in a bayes way.
 - [ ] Official suggesting that:
	```
	Deprecated: tf.keras.preprocessing APIs do not operate on tensors and are not recommended for new code. Prefer loading data with either tf.keras.utils.text_dataset_from_directory or tf.keras.utils.image_dataset_from_directory, and then transforming the output tf.data.Dataset with preprocessing layers. These approaches will offer better performance and intergration with the broader Tensorflow ecosystem. For more information, see the tutorials for [loading text]( https://www.tensorflow.org/tutorials/load_data/text), [loading images]( https://www.tensorflow.org/tutorials/load_data/images), and [augmenting images]( https://www.tensorflow.org/tutorials/images/data_augmentation), as well as the [preprocessing layer guide]( https://www.tensorflow.org/guide/keras/preprocessing_layers).
	```

# What I want to do in future
 - [ ] I do not know how the numbers '1536' in traits and '813' in random selection in pictures come. Maybe it is related to model training or predicting. I should find out it some day and it can help me to know about ML. 


---
title: Current clustering method shows results unstably.[Wrong!]
tags:
  - daily work
  - image clustering
  - kailan
categories:
  - diaries
date: 05-24-2023
---
# What I have done today

1. Installed R packages `inborutils` and `devtools` for downloading the large file of  [2022SE](https://resjournals.onlinelibrary.wiley.com/doi/abs/10.1111/syen.12543) from `zenodo`, but the file had been downloaded by `zenodo_get` and `wget`. Considering `devtools` is a useful package for R, it does not seem to waste time for me.
2. Compared trees of outgroup with different parameters and all of them are different. The whole dataset is still downloading because the network connection of `zenodo` is not stably. 
3. Symmetric difference had been calculated by paup with command `treedist` and the `normD` (normalized different, maybe?) within inceptionResnetV2 model was 1, the largest number. **It is not a acceptable result.**
4. The SSI calculation in supplemental file 3 needs a special input format of data contained node information of trees, which may be built by paup. 
5. Prepared for trip of Shennongjia in Hubei. 

# What I need to do next

 - [x] I do not understand the meaning of 'random consensus tree' and 'consensus tree' in the article.


---
title: Use whole dataset for testing image clustering
tags:
  - daily work
  - image clustering
  - kailan
categories:
  - diaries
date: 05-28-2023
---
# What I have done today

1. Downloaded the whole dataset contain 3792 pictures into `$DIR/raw` and disable its write permission.Renamed files to use '\_' to replace the spaces in files' name by `rename \_  *`.  Used a shell script to re-organize pictures by species: 
	```
	#! /usr/bin/zsh
	
	DIR=`pwd`
	
	# create species-based organized directory if it is not exist
	if [  ! -e $DIR/organized ]
	then
		mkdir $DIR/organized
		cd $DIR/organized
		mkdir `ls $DIR/raw | awk -F _ '{printf "%s_%s\n", $1,$2 }' | uniq`
	fi
	
	
	cd $DIR;
	for i in `ls $DIR/raw`
	do
		spname=`echo $i | awk -F _ '{printf "%s_%s", $1,$2}'`
		cp $DIR/raw/$i  $DIR/organized/$spname
	done;
	```
	Used a shell script for checking if the copy result contain all pictures.
	```
	s=0; 
	for i in `ls organized\`; 
	do 
		 ((s+=`ls organized/$i| wc -l`)); 
	done;
	echo $s;
	``` 
2. Used the whole dataset to extract traits and build phylogeny tree with python script. The dataset contain some broken pictures and python cannot read, so use script from [here](https://blog.csdn.net/qq_44936246/article/details/117962404) to find them out and remove them.
3. I found that the model tree is named `<model_name>.nexus` and the random tree is named `random.nexus` and I was wrong that I placed the model tree under the `../` directory, so I had always used the random trees for checking. I checked the model trees build by the whole dataset, results can be found below:
	
	<div align=center>
	<img src="/Pictures/ir100.png" width="500" />
	<br>
	    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
	    display: inline-block;
	    color: #999;
	    padding: 2px;">
	      Consensus tree of 100 trees built by inceptionResnetV2 model 
	</div>
	</div>
	
	<div align=center>
	<img src="/Pictures/ir1011.png" width="500" />
	<br>
	    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
	    display: inline-block;
	    color: #999;
	    padding: 2px;">
	      Consensus tree of 1011 trees built by inceptionResnetV2 model 
	</div>
	</div>
> "At each internal node is an indication of how often the corresponding group (meaning all taxa descending from that internal node) was found in the set of all trees. (Numbers are percentages)."   [ref](https://teaching.healthtech.dtu.dk/22115/index.php/Consensus_Trees)



# What I need to do next

 - [ ] Build 10000 trees in one week and check it.


---
title: Continuous traits phylogenetic analysis software installation
tags:
  - daily work
  - continuous trait phylogenetic analysis
  - kailan
  - image clustering
categories:
  - diaries
date: 05-30-2023
---
# What I have done today

1. Continuous traits do not appear to be analysis by mrbayes software so I searched other methods and list below:
	1. Beast 2, which is re-write from Beast 1.x and contain more model than version 1. It also can be called in program R. [see](https://github.com/BEAST2-Dev/beast-geo/releases/download/v1.2.0/phylogeography_s.pdf)
	2. R package `Phytools` for data simulation and modeling. [see](http://www.phytools.org/Cordoba2017/ex/5/Cont-char-models.html)
	3. RevBayes. [see](https://revbayes.github.io/tutorials/cont_traits/cont_trait_intro.html)
	4.  R package `evorates`. [see](https://github.com/bstaggmartin/evorates) (Model for traits evolutionary rates)
	So, the two useful software are Beast 2 and RevBayes. It is time to install bayesian analysis softwares and openmpi.
2. Installed `evorates` by `devtools`. Installed openmpi, mrbayes by brew and complied revbayes in mpi version locally. Complied mpich locally but I do not know how to use it with mrbayes and revbayes.

# What I need to do next
- [x] Approach Image-based data as continuous traits for phylogenetic analysis 


---
title: Bayesian anaylisis with continuous traits extracted from image
tags:
  - daily work
  - kailan
  - continuous trait phylogenetic analysis
categories:
  - diaries
date: 06-05-2023
---
# What I have done today

1. Done with using continuous traits using the Revbayes script from [here](https://datadryad.org/stash/dataset/doi:10.5061/dryad.40b70).
2. Switched the `.csv` format file of traits into `.nexus` format for bayesian analysis with script of myself. Re-organize `csv` files and use [script](c2n) for directly switching and [script](c2n_s) for switching selected number pictures and [script](c2n_culculate_mean) for calculate the mean traits.
3. Bayesian phylogenetic tree had been built using average continuous traits of 26 species.

<div align=center>
<img src="/Pictures/mean.png" width="500" />
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
      Phylogenetic tree of 26 species using average traits of image
</div>
</div>
4. Re-trained inceptionResnetV2 model with 499x499 pix pictures instead of 299.

# What I need to do next
- [ ] Arithmetic average cannot represent the average level of image features. I should use another method.
- [ ]  Evolution model of continuous trait can or cannot be change for better use of image?
- [ ] Are the traits extracted by models the ones I want? Should I train, even build, my own model? Or should I use model for trait extraction? The distance in the kailan-article, what exactly mean in physical or biological?

## 2023/12/12 (8.5h)
### Doing tasks
- finish phylobayes for gdl(0.5h)

### Done tasks
- P3 GTR for gdl (6.5h)
- download statistic_exercise (0.2h)
- install rust (0.1h)
- test rust (1.0h)
- config todo-daily for my blog (0.1h)
- config todo/rust for my blog(0.1h)

### Todo tasks in this week (On Friday, next week scheduled tasks)
- install conda or mamba again
- find a rust-base blog engine
- understanding the statistic_exercise and done with it
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程

### Memo & Comments


---
## 2023/12/14 (7.0h)
### Doing tasks
- test topology for gdl (2.0h)

### Done tasks
- finish phylobayes for gdl (1.0h)
- install conda or mamba again (0.5h)
- find a rust-base blog engine (0.5h)
- understanding the statistic_exercise and done with it (3.0h)

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- write MH within gibbs script in R

### Memo & Comments

---
## 2023/12/15 (7.0h)
### Doing tasks
- write MH within gibbs script in R (3.0h)

### Done tasks
- test topology for gdl (1.0h)
- install a theme for zola  (1.0h)
- learn about MCMC and MH/gibbs in R (2.0h)

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- switch my blog to zola

### Memo & Comments

---
## 2023/12/18 (12.5h)
### Doing tasks
- build a molecular data pippe line approach (1.0h)
- learning model adding and config in revbayes (1.0h)

### Done tasks
- write MH within gibbs script in R (3.0h)
- switch my blog to zola (0.5h)
- solve the problem with object function (2.0h)
- complete MH gibbs in R with GPT`s help (5.0h)

### Todo tasks in this week (On Friday, next week scheduled tasks)
- make a model list for revbayes P3
- reading papers about 本质过程

### Memo & Comments


---
## 2023/12/19 (8.0h)
### Doing tasks
- learning model adding and config in revbayes (1.0h)
- reading papers about 本质过程 (5.0h)

### Done tasks
- 本质过程思路整理 (2.0h)

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- make a model list for revbayes P3
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- 看一下共同个体/共同物种概念方面的内容，和MSC是不是一样的

### Memo & Comments


---
## 2023/12/20 (0.0h)
### Doing tasks

### Done tasks

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- 看一下共同个体/共同物种概念方面的内容，和MSC是不是一样的

### Memo & Comments





---
## 2023/12/26 (5.0h)
### Doing tasks

### Done tasks
- leafhopper infer_base P3 (5.0h)

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- 看一下共同个体/共同物种概念方面的内容，和MSC是不是一样的
- group will ppt
- model build and calculate

### Memo & Comments





---
## 2023/12/27 (0.0h)
### Doing tasks

### Done tasks
- group will ppt

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- 看一下共同个体/共同物种概念方面的内容，和MSC是不是一样的
- model build and calculate

### Memo & Comments





---
## 2023/12/28 (0.0h)
### Doing tasks

### Done tasks
- 看一下共同个体/共同物种概念方面的内容，和MSC是不是一样的

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- model build and calculate

### Memo & Comments





---
## 2023/12/29 (0.0h)
### Doing tasks

### Done tasks

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- model build and calculate
- 完整描述我的模型
- 描述计算方法
- 实践一下然后调整

### Memo & Comments



---
## 2024/01/11 (0.0h)
### Doing tasks

### Done tasks

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- model build and calculate
- 完整描述我的模型
- 描述计算方法
- 实践一下然后调整
- learning mcmctree and beast for molecular dating principle
- build my model in notebook

### Memo & Comments





---
## 2024/01/23 (0.0h)
### Doing tasks

### Done tasks

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- model build and calculate
- 完整描述我的模型
- 描述计算方法
- 实践一下然后调整
- learning mcmctree and beast for molecular dating principle
- build my model in notebook
- ascp

### Memo & Comments





---
## 2024/01/31 (0.0h)
### Doing tasks

### Done tasks

### Todo tasks in this week (On Friday, next week scheduled tasks)
- build a molecular data pippe line approach
- learning model adding and config in revbayes
- make a model list for revbayes P3
- reading papers about 本质过程
- 输入文件格式，即数据来源
- 构建0演化，然后逐步添加变量因素
- model build and calculate
- 完整描述我的模型
- 描述计算方法
- 实践一下然后调整
- learning mcmctree and beast for molecular dating principle
- build my model in notebook
- ascp 批量下载基因

### Memo & Comments
